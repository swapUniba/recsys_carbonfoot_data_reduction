{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for i in range(1, 11):\n",
    "    name_folder = f'amazon_books_60core/amazon_books_60core_split_{i}'\n",
    "    os.makedirs(name_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>rating:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1TT4CY55WLHAR</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1NPNGWBVD9AK3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWLFVCT9128JV</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id:token item_id:token  rating:float\n",
       "0  A2S166WSCFIFP5    000100039X             5\n",
       "1  A2XQ5LZHTD4AFT    000100039X             5\n",
       "2  A1TT4CY55WLHAR    000100039X             5\n",
       "3  A1NPNGWBVD9AK3    000100039X             5\n",
       "4   AWLFVCT9128JV    000100039X             5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172696\n",
      "293175\n",
      "22155 54458\n",
      "22125 53959\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('amazon_books_60core/amazon_books_60core/amazon_books_60core.inter', sep='\\t')\n",
    "amz_train, amz_test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "amz_valid = pd.DataFrame({'user_id:token': [], 'item_id:token': [], 'label:float': []})\n",
    "\n",
    "display(dataset.head(5))\n",
    "\n",
    "print(len(amz_train))\n",
    "print(len(amz_test))\n",
    "\n",
    "full_users = set(dataset['user_id:token'])\n",
    "full_items = set(dataset['item_id:token'])\n",
    "\n",
    "train_users = set(amz_train['user_id:token'])\n",
    "train_items = set(amz_train['item_id:token'])\n",
    "\n",
    "print(len(full_users), len(full_items))\n",
    "print(len(train_users), len(train_items))\n",
    "\n",
    "amz_train.to_csv('amazon_books_60core/amazon_books_60core/amazon_books_60core.train.inter', sep='\\t', index=False)\n",
    "amz_test.to_csv('amazon_books_60core/amazon_books_60core/amazon_books_60core.test.inter', sep='\\t', index=False)\n",
    "amz_valid.to_csv('amazon_books_60core/amazon_books_60core/amazon_books_60core.valid.inter', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 1: 117269\n",
      "len 2: 234538\n",
      "len 3: 351807\n",
      "len 4: 469076\n",
      "len 5: 586345\n",
      "len 6: 703614\n",
      "len 7: 820883\n",
      "len 8: 938152\n",
      "len 9: 1055421\n",
      "len 10: 1172690\n"
     ]
    }
   ],
   "source": [
    "def create_subsets_dataframe(dataframe, num_subsets):\n",
    "    subsets = []\n",
    "    subset_size = len(dataframe) // num_subsets\n",
    "\n",
    "    shuffled_dataframe = dataframe.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    for i in range(1, num_subsets + 1):\n",
    "        subset = shuffled_dataframe.head(i * subset_size)\n",
    "        subset = subset.sort_values(by=['user_id:token','item_id:token'], ascending=[True, True])\n",
    "        subsets.append(subset)\n",
    "    \n",
    "    return subsets\n",
    "\n",
    "\n",
    "data = pd.read_csv('amazon_books_60core/amazon_books_60core.train.inter', sep='\\t')\n",
    "num_subsets = 10\n",
    "\n",
    "resulting_subsets = create_subsets_dataframe(data, num_subsets)\n",
    "\n",
    "for i, subset in enumerate(resulting_subsets):\n",
    "    print(f'len {i+1}: {len(subset)}')\n",
    "    subset.to_csv(f'amazon_books_60core_split_{i+1}/amazon_books_60core_split_{i+1}.train.inter', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t 76456\n",
      "2 \t 87352\n",
      "3 \t 91648\n",
      "4 \t 93372\n",
      "5 \t 94100\n",
      "6 \t 95102\n",
      "7 \t 95608\n",
      "8 \t 95928\n",
      "9 \t 96261\n",
      "10 \t 96365\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "for i in range(1, 11):\n",
    "\n",
    "    kg = pd.read_csv('amazon_books_60core/amazon_books_60core.kg', sep='\\t')\n",
    "    link = pd.read_csv('amazon_books_60core/amazon_books_60core.link', sep='\\t')\n",
    "\n",
    "    inter_k = pd.read_csv(f'amazon_books_60core_split_{i}/amazon_books_60core_split_{i}.train.inter', sep='\\t')\n",
    "    items_k = set(inter_k['item_id:token'])\n",
    "    entity_k = set(link[link['item_id:token'].isin(items_k)]['entity_id:token'])\n",
    "    \n",
    "    kg_k = kg[kg['head_id:token'].isin(entity_k) | kg['tail_id:token'].isin(entity_k)].sort_values(by=['head_id:token'], ascending=[True])\n",
    "    link_k = link[link['item_id:token'].isin(items_k)].sort_values(by=['item_id:token'], ascending=[True])\n",
    "\n",
    "    kg_k.to_csv(f'amazon_books_60core_split_{i}/amazon_books_60core_split_{i}.kg', sep='\\t', index=False)\n",
    "    link_k.to_csv(f'amazon_books_60core_split_{i}/amazon_books_60core_split_{i}.link', sep='\\t', index=False)\n",
    "\n",
    "    shutil.copy('amazon_books_60core/amazon_books_60core.test.inter', f'amazon_books_60core_split_{i}/amazon_books_60core_split_{i}.test.inter')\n",
    "    shutil.copy('amazon_books_60core/amazon_books_60core.valid.inter', f'amazon_books_60core_split_{i}/amazon_books_60core_split_{i}.valid.inter')\n",
    "\n",
    "    print(i,'\\t',len(kg_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "Split 1\n",
      "Number of Users: 20032\n",
      "Number of Items: 37184\n",
      "Percentage of Likes: 80.65%\n",
      "Sparsity: 0.9998\n",
      "Average Rating per User: 585.41\n",
      "Average Rating per Item: 315.37\n",
      "\n",
      "-----\n",
      "Split 2\n",
      "Number of Users: 21293\n",
      "Number of Items: 44906\n",
      "Percentage of Likes: 80.79%\n",
      "Sparsity: 0.9998\n",
      "Average Rating per User: 1101.48\n",
      "Average Rating per Item: 522.29\n",
      "\n",
      "-----\n",
      "Split 3\n",
      "Number of Users: 21669\n",
      "Number of Items: 48287\n",
      "Percentage of Likes: 80.62%\n",
      "Sparsity: 0.9997\n",
      "Average Rating per User: 1623.55\n",
      "Average Rating per Item: 728.57\n",
      "\n",
      "-----\n",
      "Split 4\n",
      "Number of Users: 21839\n",
      "Number of Items: 50180\n",
      "Percentage of Likes: 80.61%\n",
      "Sparsity: 0.9996\n",
      "Average Rating per User: 2147.88\n",
      "Average Rating per Item: 934.79\n",
      "\n",
      "-----\n",
      "Split 5\n",
      "Number of Users: 21944\n",
      "Number of Items: 51372\n",
      "Percentage of Likes: 80.63%\n",
      "Sparsity: 0.9995\n",
      "Average Rating per User: 2672.01\n",
      "Average Rating per Item: 1141.37\n",
      "\n",
      "-----\n",
      "Split 6\n",
      "Number of Users: 21999\n",
      "Number of Items: 52159\n",
      "Percentage of Likes: 80.64%\n",
      "Sparsity: 0.9994\n",
      "Average Rating per User: 3198.39\n",
      "Average Rating per Item: 1348.98\n",
      "\n",
      "-----\n",
      "Split 7\n",
      "Number of Users: 22043\n",
      "Number of Items: 52821\n",
      "Percentage of Likes: 80.65%\n",
      "Sparsity: 0.9993\n",
      "Average Rating per User: 3724.01\n",
      "Average Rating per Item: 1554.08\n",
      "\n",
      "-----\n",
      "Split 8\n",
      "Number of Users: 22075\n",
      "Number of Items: 53305\n",
      "Percentage of Likes: 80.66%\n",
      "Sparsity: 0.9992\n",
      "Average Rating per User: 4249.84\n",
      "Average Rating per Item: 1759.97\n",
      "\n",
      "-----\n",
      "Split 9\n",
      "Number of Users: 22103\n",
      "Number of Items: 53654\n",
      "Percentage of Likes: 80.64%\n",
      "Sparsity: 0.9991\n",
      "Average Rating per User: 4775.01\n",
      "Average Rating per Item: 1967.09\n",
      "\n",
      "-----\n",
      "Split 10\n",
      "Number of Users: 22125\n",
      "Number of Items: 53959\n",
      "Percentage of Likes: 80.63%\n",
      "Sparsity: 0.9990\n",
      "Average Rating per User: 5300.29\n",
      "Average Rating per Item: 2173.30\n"
     ]
    }
   ],
   "source": [
    "def stats_split(dataset):\n",
    "    interactions_df = pd.read_csv(dataset, sep='\\t')\n",
    "\n",
    "    num_users = interactions_df['user_id:token'].nunique()\n",
    "    num_items = interactions_df['item_id:token'].nunique()\n",
    "\n",
    "    num_likes = interactions_df[interactions_df['rating:float'] >= 4].shape[0]\n",
    "    total_interactions = interactions_df.shape[0]\n",
    "    percentage_likes = (num_likes / total_interactions) * 100\n",
    "\n",
    "    sparsity = 1 - (total_interactions / (num_users * num_items))\n",
    "\n",
    "    avg_rating_per_user = (total_interactions / num_users) * 100\n",
    "    avg_rating_per_item = (total_interactions / num_items) * 100\n",
    "\n",
    "    print(f\"Number of Users: {num_users}\")\n",
    "    print(f\"Number of Items: {num_items}\")\n",
    "    print(f\"Percentage of Likes: {percentage_likes:.2f}%\")\n",
    "    print(f\"Sparsity: {sparsity:.4f}\")\n",
    "    print(f\"Average Rating per User: {avg_rating_per_user:.2f}\")\n",
    "    print(f\"Average Rating per Item: {avg_rating_per_item:.2f}\")\n",
    "\n",
    "for i in range(1,11):\n",
    "    print(f'\\n-----\\nSplit {i}')\n",
    "    stats_split(f'amazon_books_60core/amazon_books_60core_split_{i}/amazon_books_60core_split_{i}.train.inter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
